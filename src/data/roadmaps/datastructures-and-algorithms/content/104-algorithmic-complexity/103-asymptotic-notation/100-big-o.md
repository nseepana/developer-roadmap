# Big O Notation

## Overview
- **Purpose**: Big O notation is a mathematical representation used in computer science to describe the performance or complexity of an algorithm.
- **Focus**: It provides an upper bound on the time complexity, indicating the worst-case scenario.

## Functionality
- **Expression**: The notation is written as O(f(n)), where:
  - **f(n)** represents a function that measures the maximum number of steps taken by an algorithm to solve a problem of size 'n'.
- **Implication**: This gives an upper limit on the time an algorithm takes to complete, relative to the input size.

## Examples
- **O(n)**: Indicates a linear relationship between the time taken and the input size.
- **O(1)**: Signifies constant time complexity, where the time is independent of the input size.

## Key Understanding
- **Approximation**: Big O notation is an approximation tool. It describes how an algorithm scales and behaves as the input size grows.
- **Not Exact Timing**: It does not provide the exact time taken for an algorithm to execute but rather the growth trend of the execution time or steps as the input size increases.
